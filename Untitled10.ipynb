{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXVtV89qsOOy1j3hIkFbsF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerrytsai961117/7022/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cmkJz0Fsgfx"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai pandas numpy scikit-learn nltk opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import opendatasets as od\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity # Scikit-learn's optimized cosine similarity\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "FuvNvQFKshbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import userdata\n",
        "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "    print(\"API key loaded from Colab Secrets.\")\n",
        "except Exception:\n",
        "    print(\"Please ensure you've set your GOOGLE_API_KEY in Colab Secrets. If not, replace 'YOUR_API_KEY' below manually.\")\n",
        "    # genai.configure(api_key=\"YOUR_API_KEY\") # Replace with your actual API key\n",
        "\n",
        "# Initialize the embedding model\n",
        "embedding_model = \"models/text-embedding-004\"\n",
        "print(f\"Embedding model '{embedding_model}' initialized.\")"
      ],
      "metadata": {
        "id": "OUkIq6-vsiUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt to download the dataset from Kaggle\n",
        "try:\n",
        "    od.download(\"https://www.kaggle.com/datasets/tharunprabu/songs-data-with-full-lyrics\")\n",
        "    df = pd.read_csv(\"songs-data-with-full-lyrics/songs_with_lyrics.csv\")\n",
        "    print(\"Dataset downloaded and loaded successfully from Kaggle!\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not download dataset from Kaggle. Error: {e}\")\n",
        "    print(\"Attempting to load from a local file path (assuming you've uploaded 'songs_with_lyrics.csv'):\")\n",
        "    try:\n",
        "        df = pd.read_csv(\"songs_with_lyrics.csv\")\n",
        "        print(\"Loaded from local file successfully!\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Could not find 'songs_with_lyrics.csv'. Creating a sample DataFrame for testing.\")\n",
        "        # Create a sample DataFrame with at least 100 entries for testing purposes\n",
        "        data = {\n",
        "            'Song Name': [f'Song {i}' for i in range(1, 151)],\n",
        "            'Artist': [f'Artist {i}' for i in range(1, 151)],\n",
        "            'Lyrics': [\n",
        "                \"This is a happy song about sunshine and flowers. Feeling good today, everything is bright.\",\n",
        "                \"A sad melody, about lost love and rainy days. Tears fall like rain.\",\n",
        "                \"Rock and roll all night, party every day. Electric guitar and loud drums.\",\n",
        "                \"Smooth jazz rhythms, chill vibes, late night city lights. Relax and unwind.\",\n",
        "                \"Hip hop beats, rhymes, and urban tales. Breaking down barriers, raising our voices.\",\n",
        "                \"Country roads, take me home, to the place I belong. Simple life, open fields.\",\n",
        "                \"Upbeat pop, dancing, feeling free. Summer nights and endless fun.\",\n",
        "                \"Another happy tune, full of joy and laughter. Life is a wonderful journey.\",\n",
        "                \"Deep thoughts, philosophical lyrics, questioning existence. The universe within.\",\n",
        "                \"Romantic ballad, hearts entwined, forever together. Love is eternal.\",\n",
        "                \"This is a happy song about sunshine and flowers. Feeling good today, everything is bright. More lyrics for a longer entry to test max_tokens. This song is truly uplifting and brings joy to my heart. The sun is shining, birds are singing, and life is beautiful. There's nothing to worry about, just pure bliss. Let's sing along and celebrate this moment. The rhythm is catchy and the melody is sweet. It's a perfect day for happiness.\",\n",
        "                \"A sad melody, about lost love and rainy days. Tears fall like rain. This is a very melancholic song, reflecting on sorrow and despair. The rain mirrors the tears falling from my eyes. There's a deep sense of longing and a heavy heart. Every note echoes the pain, a symphony of sadness. I miss you more than words can say. This feeling of emptiness consumes me. It's a dark and lonely road ahead, without you by my side. The world seems to have lost its color, fading into gray.\",\n",
        "                \"Rock and roll all night, party every day. Electric guitar and loud drums. Let's turn up the volume and let the music take control. The energy is electrifying, the crowd is roaring. We're here to rock, to shout, to let loose. No inhibitions, just pure raw power. The bass is thumping, the guitar riffs are insane. This is what living feels like, wild and free. Every beat pulses through my veins. We'll dance till dawn, till the sun comes up. This is our anthem, our rebellion. Yeah!\",\n",
        "                \"Smooth jazz rhythms, chill vibes, late night city lights. Relax and unwind. The saxophone sings a soulful tune, the piano softly plays. A gentle breeze through the open window, the city sleeps. This music soothes my soul, washes away the day's worries. A glass of wine, a comfortable chair, and perfect harmony. The night is young, and the music flows effortlessly. It's a moment of peace, of pure tranquility. Let the smooth sounds envelop you, drift away.\",\n",
        "                \"Hip hop beats, rhymes, and urban tales. Breaking down barriers, raising our voices. The streets are alive with the sound of the future. Every word is a statement, every beat a revolution. We speak our truth, we tell our stories. From the block to the top, we never stop. The rhythm takes hold, the flow is unstoppable. This is our culture, our passion. We're here to inspire, to uplift, to empower. Stand tall, stand proud, let your voice be heard.\",\n",
        "                \"Country roads, take me home, to the place I belong. Simple life, open fields. The smell of fresh cut hay, the sound of crickets at night. This is where my heart is, in the quiet embrace of nature. No hustle, no bustle, just peaceful serenity. The stars shine brighter here, a blanket of diamonds. I miss the simple things, the warmth of home. Every memory is a comfort, a gentle reminder. This land holds my roots, my history. It's a place of healing, of solace, of belonging.\",\n",
        "                \"Upbeat pop, dancing, feeling free. Summer nights and endless fun. The music makes me want to move, to jump, to shout. Every beat is a burst of energy, a surge of happiness. We're living in the moment, no regrets, just pure bliss. The lights are bright, the crowd is alive. This is the soundtrack to our perfect summer. Let's dance until we can't anymore, until the sun rises. The good times are here to stay, forever young. This feeling is electrifying, exhilarating. Yeah!\",\n",
        "                \"Another happy tune, full of joy and laughter. Life is a wonderful journey. Every step is an adventure, every day a new beginning. I'm grateful for every moment, every smile. The world is full of beauty, if you just open your eyes. Let's spread kindness, spread love, spread happiness. The positive vibes are contagious, let them flow. This song is a celebration of life, of all its wonders. Embrace the journey, enjoy the ride. It's a beautiful world, let's make it even better.\",\n",
        "                \"Deep thoughts, philosophical lyrics, questioning existence. The universe within. What is our purpose, our meaning? The stars gaze back, silent witnesses. We are but dust, yet we hold infinitude. The mysteries of life unfold with every breath. Search for truth, search for understanding. The path is long, the questions endless. This song invites contemplation, introspection. Look within, find your answers. The journey of self-discovery is profound.\",\n",
        "                \"Romantic ballad, hearts entwined, forever together. Love is eternal. Your hand in mine, walking through life's garden. Every moment with you is precious, a treasure. Our love story, written in the stars. Two souls, one heart, forever bound. The melody whispers promises, the lyrics sing of devotion. This is more than a song, it's our anthem. Through thick and thin, we'll always be together. Our love is a flame, burning bright, never fading.\"\n",
        "            ] + [f\"This is a generic song about various topics {i}. It has some random words and phrases to fill up the content for testing purposes. More text to ensure sufficient length for the dataset, reaching over 100 entries. Blah blah blah. Keywords: generic, random, text, test, long, fill, content.\" for i in range(11, 151)]\n",
        "        }\n",
        "        df = pd.DataFrame(data)\n",
        "        print(\"Created a sample DataFrame for testing.\")\n",
        "\n",
        "# Ensure 'Lyrics' column exists before proceeding\n",
        "if 'Lyrics' not in df.columns or df['Lyrics'].empty:\n",
        "    print(\"Error: 'Lyrics' column is missing or empty. Cannot proceed with embedding generation.\")\n",
        "    exit() # Exit if essential column is missing\n",
        "\n",
        "# Define text cleaning function\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to 'Lyrics' column\n",
        "df['Cleaned_Lyrics'] = df['Lyrics'].apply(preprocess_text)\n",
        "\n",
        "# Filter out any entries where Cleaned_Lyrics might have become empty after preprocessing\n",
        "df_processed = df[df['Cleaned_Lyrics'].str.strip() != ''].reset_index(drop=True)\n",
        "print(f\"\\nNumber of valid entries after preprocessing: {len(df_processed)}\")\n",
        "\n",
        "if len(df_processed) < 50:\n",
        "    print(\"Warning: Less than 50 valid entries after preprocessing. Embeddings might not be representative.\")"
      ],
      "metadata": {
        "id": "g6nsGp4CsjTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select text entries for embedding\n",
        "# We'll embed up to the first 200 entries to manage API calls and runtime efficiently.\n",
        "# If your dataset is smaller, it will use all available valid entries.\n",
        "texts_to_embed = df_processed['Cleaned_Lyrics'].tolist()\n",
        "num_entries_to_embed = min(len(texts_to_embed), 200) # Process max 200 entries\n",
        "texts_to_embed_subset = texts_to_embed[:num_entries_to_embed]\n",
        "\n",
        "print(f\"Generating embeddings for {len(texts_to_embed_subset)} text entries.\")\n",
        "\n",
        "all_embeddings = []\n",
        "# It's good practice to chunk requests for very large datasets to avoid API limits.\n",
        "# For 200 entries, a single call is usually fine.\n",
        "try:\n",
        "    response = genai.embed_content(\n",
        "        model=embedding_model,\n",
        "        contents=texts_to_embed_subset,\n",
        "        task_type=\"SEMANTIC_SIMILARITY\"\n",
        "    )\n",
        "    all_embeddings = [np.array(e.values) for e in response.embeddings]\n",
        "    print(f\"Successfully generated {len(all_embeddings)} embeddings.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error generating embeddings: {e}\")\n",
        "    all_embeddings = []\n",
        "\n",
        "# Convert the list of NumPy arrays into a single 2D NumPy array\n",
        "if all_embeddings:\n",
        "    embeddings_array = np.array(all_embeddings)\n",
        "    print(f\"\\nEmbeddings stored as a NumPy array with shape: {embeddings_array.shape}\")\n",
        "\n",
        "    # Attach embeddings to the DataFrame for easier access\n",
        "    df_processed = df_processed.head(len(all_embeddings)).copy() # Ensure df_processed length matches embeddings\n",
        "    df_processed['embedding'] = list(all_embeddings)\n",
        "    print(\"\\nEmbeddings attached to the DataFrame.\")\n",
        "else:\n",
        "    print(\"\\nNo embeddings were generated. Cannot proceed with similarity search.\")\n",
        "    exit() # Exit if no embeddings are available"
      ],
      "metadata": {
        "id": "AUJvIPHTskbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_songs(target_song_index, embeddings_df, top_n=5):\n",
        "    \"\"\"\n",
        "    Finds the top N most similar songs based on cosine similarity of their embeddings.\n",
        "\n",
        "    Args:\n",
        "        target_song_index (int): The index of the song in the DataFrame for which to find recommendations.\n",
        "        embeddings_df (pd.DataFrame): DataFrame containing 'Song Name', 'Artist', and 'embedding' columns.\n",
        "        top_n (int): The number of top similar songs to recommend.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame of the top_n most similar songs (excluding the target song itself).\n",
        "                      Includes 'Song Name', 'Artist', and 'Similarity_Score'.\n",
        "    \"\"\"\n",
        "    if target_song_index >= len(embeddings_df) or target_song_index < 0:\n",
        "        print(f\"Error: Target song index {target_song_index} is out of bounds.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    target_embedding = embeddings_df.loc[target_song_index, 'embedding']\n",
        "    # Ensure target_embedding is a 2D array for cosine_similarity if it's a single vector\n",
        "    if target_embedding.ndim == 1:\n",
        "        target_embedding = target_embedding.reshape(1, -1)\n",
        "\n",
        "    # Calculate cosine similarity between the target embedding and all other embeddings\n",
        "    # sklearn.metrics.pairwise.cosine_similarity expects 2D arrays\n",
        "    # so we need to reshape single embeddings (1, embedding_dim)\n",
        "    all_embeddings_matrix = np.array(embeddings_df['embedding'].tolist())\n",
        "\n",
        "    similarities = cosine_similarity(target_embedding, all_embeddings_matrix).flatten()\n",
        "\n",
        "    # Create a Series with similarities, indexed by song index\n",
        "    similarity_scores = pd.Series(similarities, index=embeddings_df.index)\n",
        "\n",
        "    # Exclude the target song itself from recommendations\n",
        "    similarity_scores = similarity_scores.drop(index=target_song_index)\n",
        "\n",
        "    # Sort by similarity in descending order and get the top N\n",
        "    top_similar_indices = similarity_scores.nlargest(top_n).index\n",
        "\n",
        "    # Retrieve the details of the recommended songs\n",
        "    recommendations = embeddings_df.loc[top_similar_indices, ['Song Name', 'Artist']].copy()\n",
        "    recommendations['Similarity_Score'] = similarity_scores.loc[top_similar_indices]\n",
        "\n",
        "    return recommendations.reset_index(drop=True)\n",
        "\n",
        "print(\"`find_similar_songs` function defined.\")"
      ],
      "metadata": {
        "id": "CrYmEYKesle5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a song to get recommendations for\n",
        "# Let's pick an arbitrary song, e.g., the 5th song (index 4)\n",
        "# Make sure the chosen index exists in df_processed\n",
        "if len(df_processed) > 4:\n",
        "    test_song_index = 4\n",
        "    test_song_name = df_processed.loc[test_song_index, 'Song Name']\n",
        "    test_artist = df_processed.loc[test_song_index, 'Artist']\n",
        "\n",
        "    print(f\"\\nFinding top 5 similar songs to: '{test_song_name}' by {test_artist}\\n\")\n",
        "\n",
        "    # Get recommendations\n",
        "    top_recommendations = find_similar_songs(test_song_index, df_processed, top_n=5)\n",
        "\n",
        "    if not top_recommendations.empty:\n",
        "        print(\"Top 5 Recommended Songs:\")\n",
        "        print(top_recommendations.to_string(index=False)) # Use to_string to print full DataFrame without index\n",
        "    else:\n",
        "        print(\"Could not retrieve recommendations. Check logs above for errors.\")\n",
        "else:\n",
        "    print(\"\\nDataset too small to pick a test song at index 4. Please ensure at least 5 songs are loaded.\")"
      ],
      "metadata": {
        "id": "1ktZhti4smo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try another one, maybe a song from the middle or end of your processed dataset\n",
        "if len(df_processed) > 50: # Ensure there are enough songs for a different index\n",
        "    test_song_index_2 = 50 # Example: the 51st song\n",
        "    test_song_name_2 = df_processed.loc[test_song_index_2, 'Song Name']\n",
        "    test_artist_2 = df_processed.loc[test_song_index_2, 'Artist']\n",
        "\n",
        "    print(f\"\\n--- Finding top 5 similar songs to: '{test_song_name_2}' by {test_artist_2} ---\\n\")\n",
        "\n",
        "    top_recommendations_2 = find_similar_songs(test_song_index_2, df_processed, top_n=5)\n",
        "\n",
        "    if not top_recommendations_2.empty:\n",
        "        print(\"Top 5 Recommended Songs:\")\n",
        "        print(top_recommendations_2.to_string(index=False))\n",
        "    else:\n",
        "        print(\"Could not retrieve recommendations for the second test song.\")"
      ],
      "metadata": {
        "id": "MlKFk_Bmsnm6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}